{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "nb1"
    ]
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Installing dependencies \n",
    "# %pip install tensorflow\n",
    "# %pip install tensorflow-gpu\n",
    "# %pip install opencv-python\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 12:10:59.669095: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-14 12:10:59.669122: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-14 12:10:59.669975: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-14 12:10:59.757616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D,  MaxPooling2D, MaxPool2D,Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imghdr\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgHieght = 256\n",
    "imgWidth = 256\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "lossMethod = keras.losses.categorical_crossentropy\n",
    "labelMode = 'categorical'\n",
    "size = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the path of repective datasets\n",
    "\n",
    "trainDataPath   = './dataset/train/'\n",
    "testDataPath    = './dataset/test/'\n",
    "validationPath  = './dataset/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading complete train data\n",
    "CompleteTrainDataSet = tf.keras.utils.image_dataset_from_directory(trainDataPath,label_mode=labelMode,image_size=(imgHieght,imgWidth))\n",
    "\n",
    "## scaling pixel in the range [0,1]\n",
    "scaledCompleteTrainDataSet = CompleteTrainDataSet.map(lambda x,y:(x/255,y))\n",
    "\n",
    "## ClassNames\n",
    "classNames = CompleteTrainDataSet.class_names\n",
    "\n",
    "## iterator to move from one batch to another \n",
    "dataIterator = scaledCompleteTrainDataSet.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationData = tf.keras.utils.image_dataset_from_directory(validationPath,label_mode=labelMode,image_size=(imgHieght,imgWidth))\n",
    "\n",
    "scaledValidationData = validationData.map(lambda x,y:(x/255,y))\n",
    "\n",
    "validationData = scaledValidationData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating one batch\n",
    "batch = dataIterator.next()\n",
    "print(\"size of one batch is \",batch[0].shape[0])\n",
    "print(\"size of image is : \",batch[0].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## min / max value of pixel\n",
    "print(\"Scaling result\")\n",
    "print(\"max ==>\",batch[0].max())\n",
    "print(\"min ==>\",batch[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing Indexes and repective class Names for batch\n",
    "for i in batch[1][:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Visualization\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in CompleteTrainDataSet.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    if labelMode == 'int':\n",
    "      plt.title(CompleteTrainDataSet.class_names[labels[i]])\n",
    "    else:\n",
    "      plt.title(CompleteTrainDataSet.class_names[np.argmax(labels[i])])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Splitting train data into small part**\n",
    "\n",
    "    - Splitting Big training data into 5 parts \n",
    "    - Total 625 batches [20000 images] are present\n",
    "    - Making 5 parts of 125 batch each\n",
    "    - Each batch contains 32 images group\n",
    "    - Each group contains 4000 images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupSize = int(len(CompleteTrainDataSet)*size)\n",
    "\n",
    "trainData_0 = scaledCompleteTrainDataSet.take(groupSize)\n",
    "trainData_1 = scaledCompleteTrainDataSet.skip(groupSize).take(groupSize)\n",
    "trainData_2 = scaledCompleteTrainDataSet.skip(groupSize*2).take(groupSize)\n",
    "trainData_3 = scaledCompleteTrainDataSet.skip(groupSize*3).take(groupSize)\n",
    "trainData_4 = scaledCompleteTrainDataSet.skip(groupSize*4).take(groupSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_0 = trainData_0.as_numpy_iterator().next()\n",
    "batch_1 = trainData_1.as_numpy_iterator().next()\n",
    "batch_2 = trainData_2.as_numpy_iterator().next()\n",
    "batch_3 = trainData_3.as_numpy_iterator().next()\n",
    "batch_4 = trainData_4.as_numpy_iterator().next()\n",
    "print(len(trainData_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [batch_0,batch_1,batch_2,batch_3,batch_4]\n",
    "for batch in batches:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "batch_0[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to evaluate the performance of model\n",
    "\n",
    "def plotLoss(history):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['loss'],color='teal',label='loss')\n",
    "    plt.plot(history.history['val_loss'],color='orange',label='val_loss')\n",
    "    fig.suptitle('loss',fontsize=20)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plotAccuracy(history):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(history.history['accuracy'],color='teal',label='Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'],color='orange',label='val_accuracy')\n",
    "    fig.suptitle('Accuracy',fontsize=20)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 0 \n",
    "\n",
    "model_0 = Sequential() \n",
    "\n",
    "model_0.add(Conv2D(16,(3,3),1,activation='relu',input_shape=(imgHieght,imgWidth,3)))\n",
    "model_0.add(MaxPool2D())\n",
    "\n",
    "model_0.add(Conv2D(32,(3,3),1,activation='relu'))\n",
    "model_0.add(MaxPool2D())\n",
    "\n",
    "model_0.add(Conv2D(64,(3,3),1,activation='relu'))\n",
    "model_0.add(MaxPool2D())\n",
    "\n",
    "model_0.add(Flatten())\n",
    "\n",
    "model_0.add(Dense(256,activation='relu'))\n",
    "model_0.add(Dense(4,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.compile(optimizer,loss=lossMethod,metrics=['accuracy'])\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_0 = model_0.fit(trainData_0,epochs=5,validation_data=validationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(hist_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAccuracy(hist_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv2D(16,(3,3),1,activation='relu',input_shape=(imgHieght,imgWidth,3)))\n",
    "model_1.add(MaxPool2D())\n",
    "\n",
    "model_1.add(Conv2D(32,(3,3),1,activation='relu'))\n",
    "model_1.add(MaxPool2D())\n",
    "\n",
    "model_1.add(Conv2D(64,(3,3),1,activation='relu'))\n",
    "model_1.add(MaxPool2D())\n",
    "\n",
    "model_1.add(Flatten())\n",
    "\n",
    "model_1.add(Dense(256,activation='relu'))\n",
    "model_1.add(Dense(128,activation='relu'))\n",
    "model_1.add(Dense(4,activation='softmax'))\n",
    "\n",
    "model_1.compile(optimizer=optimizer,loss=lossMethod,metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_1 = model_1.fit(trainData_1,epochs=5,validation_data=validationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLoss(hist_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAccuracy(hist_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(imgHieght,imgWidth, 3)))\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), name='MaxPool1'))\n",
    "model_2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), name='MaxPool2'))\n",
    "model_2.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), name='MaxPool3'))\n",
    "\n",
    "# Flatten the output from Conv5-3 to generate a feature vector\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(256, activation='relu'))\n",
    "model_2.add(Dense(4, activation='relu'))\n",
    "\n",
    "model_2.compile(optimizer=optimizer, loss=lossMethod, metrics=['accuracy'])\n",
    "model_2.summary()\n",
    "\n",
    "hist_2 = model_2.fit(trainData_2,epochs=10,validation_data=validationData)\n",
    "plotLoss(hist_2)\n",
    "plotAccuracy(hist_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(trainedModel,train_data):\n",
    "\n",
    "    for layers in trainedModel.layers:\n",
    "        layers.trainable = False\n",
    "\n",
    "    # trainedModel.summary()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(trainedModel)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "    # print(model.summary())\n",
    "    model.compile(optimizer=optimizer,loss=lossMethod,metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data,epochs=4,validation_data=validationData)\n",
    "\n",
    "    plotLoss(history)\n",
    "    plotAccuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_Model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(imgHieght,imgWidth,3),\n",
    "    classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainModel(VGG16_Model, trainData_3)\n",
    "for layers in VGG16_Model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "    # trainedModel.summary()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(VGG16_Model)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096,activation='softmax'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "\n",
    "    # print(model.summary())\n",
    "    model.compile(optimizer=optimizer,loss=lossMethod,metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(trainData_4,epochs=4,validation_data=validationData)\n",
    "\n",
    "    plotLoss(history)\n",
    "    plotAccuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_Model= tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(imgHieght,imgWidth,3),\n",
    "    classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel(ResNet50_Model,trainData_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsMap = {}\n",
    "for image in os.listdir(testDataPath):\n",
    "\n",
    "    imagePath = os.path.join(testDataPath,image)\n",
    "\n",
    "    img = tf.keras.utils.load_img(\n",
    "        imagePath, target_size=(imgHieght,imgWidth)\n",
    "    )\n",
    "\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    predictions = model_0.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    predictionsMap[imagePath] = classNames[np.argmax(score)]  \n",
    "\n",
    "    # print(\n",
    "    #     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    #     .format(classNames[np.argmax(score)], 100 * np.max(score))\n",
    "    # )\n",
    "print(predictionsMap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
